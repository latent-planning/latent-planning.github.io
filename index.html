<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models">
  <meta name="keywords" content="Offline reinforcement learning, goal-conditioned reinforcement learning,optimal control,latent dynamics,planning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!--<script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>-->

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-WW9Q7B6L');</script>
    <!-- End Google Tag Manager -->

  <!--<script>-->
  <!--  window.dataLayer = window.dataLayer || [];-->

  <!--  function gtag() {-->
  <!--    dataLayer.push(arguments);-->
  <!--  }-->

  <!--  gtag('js', new Date());-->

  <!--  gtag('config', 'G-PYVRSFMDRL');-->
  <!--</script>-->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WW9Q7B6L"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://vladisai.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Nerfies: Deformable Neural Radiance Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://vladisai.github.io">Vlad Sobal</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://kevinghst.github.io/">Wancong Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://kyunghyuncho.me/">Kyunghyun Cho</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://randallbalestriero.github.io/">Randall Balestriero</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://timrudner.com/">Tim G. J. Rudner</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://yann.lecun.com/">Yann LeCun</a><sup>1,4</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>New York University,</span>
            <span class="author-block"><sup>2</sup>Genentech</span>
            <span class="author-block"><sup>3</sup>Brown University</span>
            <span class="author-block"><sup>4</sup>Meta FAIR</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!--[> Video Link. <]-->
              <!--<span class="link-block">-->
              <!--  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
              <!--     class="external-link button is-normal is-rounded is-dark">-->
              <!--    <span class="icon">-->
              <!--        <i class="fab fa-youtube"></i>-->
              <!--    </span>-->
              <!--    <span>Video</span>-->
              <!--  </a>-->
              <!--</span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column content">
        <h2 class="title is-4">Overview figure</h2>
        <figure class="image">
          <img src="./static/images/main_idea.png" alt="Overview figure">
        </figure>
        Test title.
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          A long-standing goal in AI is to build agents that can solve a variety of tasks across different environments, including previously unseen ones. Two dominant approaches tackle this challenge: (i) reinforcement learning (RL), which learns policies through trial and error, and (ii) optimal control, which plans actions using a learned or known dynamics model. However, their relative strengths and weaknesses remain underexplored in the setting where agents must learn from offline trajectories without reward annotations.
          </p>
          <p>In this work, we systematically analyze the performance of different RL and control-based methods under datasets of varying quality. On the RL side, we consider goal-conditioned and zero-shot approaches. On the control side, we train a latent dynamics model using the Joint Embedding Predictive Architecture (JEPA) and use it for planning. We study how dataset properties—such as data diversity, trajectory quality, and environment variability—affect the performance of these approaches.</p>
          <p>
          Our results show that model-free RL excels when abundant, high-quality data is available, while model-based planning excels in generalization to novel environment leayouts, in trajectory stitching, and data-efficiency. Notably, planning with a latent dynamics model emerges as a promising approach for zero-shot generalization from suboptimal data.</p>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{sobal2025learning,
  title={Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models},
  author={Sobal, Vlad and Zhang, Wancong and Cho, Kynghyun and Balestriero, Randall and Rudner, Tim G. J. and LeCun, Yann},
  journal={arXiv preprint arXiv:XXXX.XXXXX},
  year={2025},
  archivePrefix={arXiv},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Based on Nerfies Website (<a href="https://github.com/nerfies/nerfies.github.io">source code</a>).
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
